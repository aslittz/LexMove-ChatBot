# ================================================================
# STREAMLIT CHATBOT UYGULAMASI (app.py) - STREAMLIT CLOUD VERSIYONU
# ================================================================

import os
import sys
import subprocess
import warnings
import streamlit as st
from pathlib import Path
from typing import List

warnings.filterwarnings('ignore')

print("ğŸ“¦ ModÃ¼ller yÃ¼kleniyor...")

# LangChain bileÅŸenleri - Uyumlu import
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError:
    from langchain_community.chat_models import ChatGoogleGenerativeAI

try:
    from langchain_community.vectorstores import Chroma
except ImportError:
    from langchain.vectorstores import Chroma

try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    from langchain.embeddings import HuggingFaceEmbeddings

try:
    from langchain_core.documents import Document
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
except ImportError:
    from langchain.schema import Document
    from langchain.prompts import ChatPromptTemplate
    from langchain.schema.output_parser import StrOutputParser

print("âœ… TÃ¼m modÃ¼ller yÃ¼klendi")

# ================================================================
# SAYFA AYARLARI
# ================================================================
st.set_page_config(
    page_title="LexMove RAG Chatbot", 
    layout="centered",
    initial_sidebar_state="expanded"
)

# BaÅŸlÄ±klar
st.title("âš–ï¸ LexMove Hukuk Chatbotu")
st.markdown("TÃ¼rk Hukuku (Mini Q&A) veri seti ile desteklenen yapay zeka danÄ±ÅŸmanÄ±.")

# ================================================================
# 1. AYARLAR VE VERÄ°TABANI BAÄLANTISI
# ================================================================

# Proje iÃ§i yol kullanÄ±mÄ±
BASE_DIR = Path(__file__).parent.absolute()
CHROMA_PATH = BASE_DIR / "chroma_db_lexmove_mini"
COLLECTION_NAME = "mevzuat_chunks_mini" 
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# ================================================================
# 2. OTOMATÄ°K DATABASE KURULUMU
# ================================================================

@st.cache_resource(show_spinner=False)
def setup_database_if_needed():
    """ChromaDB yoksa otomatik oluÅŸtur"""
    
    # Database zaten varsa skip
    if CHROMA_PATH.exists():
        try:
            files = list(CHROMA_PATH.glob("*"))
            if len(files) > 0:
                return True  # Database mevcut
        except:
            pass
    
    # Database yok, oluÅŸtur
    st.info("ğŸ”„ Ä°lk kurulum yapÄ±lÄ±yor... (Bu iÅŸlem 2-3 dakika sÃ¼rebilir)")
    st.info("ğŸ“¦ Hugging Face'ten veri seti indiriliyor ve iÅŸleniyor...")
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("â³ setup_database.py Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
        progress_bar.progress(25)
        
        # setup_database.py'yi Ã§alÄ±ÅŸtÄ±r
        result = subprocess.run(
            [sys.executable, str(BASE_DIR / "setup_database.py")],
            capture_output=True,
            text=True,
            check=True
        )
        
        progress_bar.progress(75)
        status_text.text("âœ… Database oluÅŸturuldu, yÃ¼kleniyor...")
        
        # BaÅŸarÄ± kontrolÃ¼
        if CHROMA_PATH.exists() and len(list(CHROMA_PATH.glob("*"))) > 0:
            progress_bar.progress(100)
            status_text.empty()
            st.success("âœ… Database baÅŸarÄ±yla oluÅŸturuldu!")
            st.balloons()
            return True
        else:
            st.error("âŒ Database oluÅŸturulamadÄ±!")
            return False
            
    except subprocess.CalledProcessError as e:
        progress_bar.empty()
        status_text.empty()
        st.error("âŒ Database kurulum hatasÄ±!")
        st.error(f"Detay: {e.stderr}")
        st.info("ğŸ’¡ LÃ¼tfen sayfayÄ± yenileyin ve tekrar deneyin.")
        return False
    except Exception as e:
        progress_bar.empty()
        status_text.empty()
        st.error(f"âŒ Beklenmeyen hata: {str(e)}")
        return False

# ================================================================
# 3. VEKTÃ–RSTORE VE LLM YÃœKLENMESÄ°
# ================================================================

@st.cache_resource
def get_vectorstore():
    """ChromaDB vektÃ¶r veritabanÄ±nÄ± yÃ¼kler"""
    
    # Yol kontrolÃ¼
    if not CHROMA_PATH.exists():
        st.error(f"âŒ HATA: ChromaDB klasÃ¶rÃ¼ bulunamadÄ±!")
        st.error(f"ğŸ“‚ Aranan yer: {CHROMA_PATH}")
        return None
    
    # KlasÃ¶r iÃ§eriÄŸi kontrolÃ¼
    try:
        files_in_chroma = list(CHROMA_PATH.glob("*"))
        if len(files_in_chroma) == 0:
            st.error("âŒ ChromaDB klasÃ¶rÃ¼ boÅŸ!")
            return None
    except Exception as e:
        st.error(f"âŒ KlasÃ¶r okunamadÄ±: {e}")
        return None
    
    try:
        # Embeddings modelini yÃ¼kle
        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # ChromaDB'yi yÃ¼kle
        vectorstore = Chroma(
            persist_directory=str(CHROMA_PATH),
            embedding_function=embeddings,
            collection_name=COLLECTION_NAME
        )
        
        # VektÃ¶r sayÄ±sÄ±nÄ± al
        try:
            chunk_count = vectorstore._collection.count()
        except:
            chunk_count = 0
        
        if chunk_count == 0:
            st.error("âŒ ChromaDB boÅŸ! HiÃ§ vektÃ¶r bulunamadÄ±.")
            return None
        
        return vectorstore
        
    except Exception as e:
        st.error(f"âŒ ChromaDB baÄŸlantÄ± hatasÄ±:")
        st.exception(e)
        return None

@st.cache_resource
def get_llm():
    """Google Gemini LLM'i baÅŸlatÄ±r"""
    
    # Streamlit Cloud secrets'tan oku (Ã¶ncelik)
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        # Local .env'den oku
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv('GOOGLE_API_KEY')
    
    if not api_key:
        st.error("ğŸš¨ HATA: GOOGLE_API_KEY bulunamadÄ±!")
        st.info("ğŸ’¡ Streamlit Cloud iÃ§in:")
        st.code("App Settings â†’ Secrets â†’ GOOGLE_API_KEY ekleyin", language='text')
        st.info("ğŸ’¡ Yerel Ã§alÄ±ÅŸma iÃ§in:")
        st.code('GOOGLE_API_KEY=your_api_key_here', language='bash')
        st.info("API anahtarÄ± almak iÃ§in: https://ai.google.dev/")
        return None
    
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.3,
            max_output_tokens=2048,
            google_api_key=api_key
        )
        return llm
    except Exception as e:
        st.error(f"âŒ LLM baÅŸlatma hatasÄ±:")
        st.exception(e)
        st.info("ğŸ’¡ API anahtarÄ±nÄ±zÄ±n geÃ§erli olduÄŸundan emin olun")
        return None

# ================================================================
# SÄ°STEM BAÅLATMA
# ================================================================

# Sidebar bilgileri
with st.sidebar:
    st.markdown("### ğŸ”§ Sistem Durumu")
    
    # Database durumu
    if CHROMA_PATH.exists() and len(list(CHROMA_PATH.glob("*"))) > 0:
        st.success("âœ… Database aktif")
    else:
        st.warning("â³ Database kurulumu gerekli")

# Database kurulumunu kontrol et
with st.spinner("ğŸ”„ Sistem hazÄ±rlanÄ±yor..."):
    db_ready = setup_database_if_needed()
    
    if not db_ready:
        st.error("âŒ Sistem baÅŸlatÄ±lamadÄ±. LÃ¼tfen sayfayÄ± yenileyin.")
        st.stop()

# Sistemleri baÅŸlat
with st.spinner("ğŸ“¦ BileÅŸenler yÃ¼kleniyor..."):
    vectorstore = get_vectorstore()
    llm = get_llm()

# Sidebar gÃ¼ncellemeleri
with st.sidebar:
    if vectorstore:
        try:
            chunk_count = vectorstore._collection.count()
            st.metric("ğŸ“Š Toplam VektÃ¶r", f"{chunk_count:,}")
        except:
            pass
    
    if llm:
        st.success("âœ… LLM hazÄ±r (Gemini 2.0)")
    else:
        st.error("âŒ LLM baÅŸlatÄ±lamadÄ±")

# ================================================================
# 4. RAG FONKSÄ°YONLARI VE ZÄ°NCÄ°RÄ°
# ================================================================

def format_docs(docs: List[Document]) -> str:
    """Ã‡ekilen document listesini tek bir string baÄŸlamÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    if not docs:
        return "Ä°lgili bilgi bulunamadÄ±."
    return "\n\n---\n\n".join(doc.page_content for doc in docs)

def retrieve_relevant_chunks(query: str, k: int = 8) -> List[Document]:
    """Sorguya gÃ¶re ChromaDB'den en alakalÄ± parÃ§alarÄ± Ã§eker."""
    if vectorstore is None:
        return []
    try:
        return vectorstore.similarity_search(query=query, k=k)
    except Exception as e:
        st.error(f"âŒ VektÃ¶r arama hatasÄ±: {e}")
        return []

# Prompt Åablonu
RAG_PROMPT_TEMPLATE = """
Sen, TÃ¼rk hukuku konusunda uzmanlaÅŸmÄ±ÅŸ, yapay zeka destekli bir danÄ±ÅŸmansÄ±n.
GÃ¶revinde sadece, sana aÅŸaÄŸÄ±da saÄŸlanan 'BAÄLAM' iÃ§erisindeki bilgileri kullanmalÄ±sÄ±n.
EÄŸer BAÄLAM'daki bilgiler soruyu yanÄ±tlamak iÃ§in yeterli deÄŸilse, kesinlikle uydurma yapma veya genel bilgi verme.
BÃ¶yle bir durumda cevabÄ±n "Maalesef elimdeki mevzuat metinlerinde sorunuzun cevabÄ±na uygun bir yanÄ±t bulamadÄ±m..." olmalÄ±dÄ±r.

AÅŸaÄŸÄ±daki kurallara kesinlikle uy:
1. CevaplarÄ±nÄ± TÃ¼rkÃ§e ve kibar bir dille ver.
2. CevabÄ±nÄ± BAÄLAM'daki bilgilere dayandÄ±rarak oluÅŸtur.
3. YanÄ±tÄ±n, Ã§ekilen BAÄLAM'daki en detaylÄ± ve aÃ§Ä±klayÄ±cÄ± bilgi parÃ§asÄ±nÄ± iÃ§ermeli ve bu bilgiyi olabildiÄŸince eksiksiz sunmalÄ±dÄ±r.
4. Ã‡ekilen BAÄLAM'daki hukuki aÃ§Ä±klamanÄ±n tamamÄ±nÄ± kullanmaya Ã§alÄ±ÅŸ.
5. KÄ±sa ve net cevaplar ver, gereksiz tekrar yapma.

BAÄLAM:
{context}

KULLANICININ SORUSU:
{question}

SENÄ°N YANITIN:
"""

RAG_PROMPT = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)

# RAG Zinciri oluÅŸtur
if llm and vectorstore:
    rag_chain = (
        {
            "context": lambda x: format_docs(retrieve_relevant_chunks(x["question"])),
            "question": lambda x: x["question"]
        }
        | RAG_PROMPT 
        | llm 
        | StrOutputParser()
    )
else:
    rag_chain = None

# ================================================================
# 5. STREAMLIT ARAYÃœZÃœ
# ================================================================

# Sohbet geÃ§miÅŸini baÅŸlat
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "assistant", 
            "content": "Merhaba! TÃ¼rk hukuku ile ilgili sorularÄ±nÄ±zÄ± cevaplayabilirim. NasÄ±l yardÄ±mcÄ± olabilirim? ğŸ“š"
        }
    ]

# Sohbet geÃ§miÅŸini gÃ¶ster
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# KullanÄ±cÄ± giriÅŸi
user_input = st.chat_input(placeholder="Hukuki sorunuzu buraya yazÄ±n...")

if user_input:
    # Sistem hazÄ±r deÄŸilse uyarÄ± ver
    if not rag_chain:
        st.error("âš ï¸ Sistem henÃ¼z hazÄ±r deÄŸil. LÃ¼tfen yukarÄ±daki hatalarÄ± kontrol edin.")
        st.stop()
    
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # YanÄ±tÄ± al
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Mevzuat taranÄ±yor..."):
            try:
                # RAG Zincirini Ã§aÄŸÄ±r
                response = rag_chain.invoke({"question": user_input})
                
                # YanÄ±tÄ± gÃ¶ster
                st.write(response)
                
                # Asistan yanÄ±tÄ±nÄ± kaydet
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response
                })
                
            except Exception as e:
                error_msg = f"âš ï¸ Bir hata oluÅŸtu: {str(e)}"
                st.error(error_msg)
                st.info("ğŸ’¡ BirkaÃ§ saniye bekleyip tekrar deneyin veya sorunuzu yeniden ifade edin.")
                
                # Hata mesajÄ±nÄ± kaydet
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": error_msg
                })

# ================================================================
# 6. SIDEBAR BÄ°LGÄ°LERÄ°
# ================================================================

with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ“– KullanÄ±m Ä°puÃ§larÄ±")
    st.markdown("""
    - TÃ¼rk hukuku hakkÄ±nda soru sorun
    - Net ve spesifik sorular sorun
    - Sistem sadece veri setindeki bilgileri kullanÄ±r
    """)
    
    st.markdown("---")
    st.markdown("### â„¹ï¸ Proje Bilgileri")
    st.markdown("""
    **LexMove RAG Chatbot**
    
    - ğŸ¤– Model: Gemini 2.0 Flash
    - ğŸ“Š Vector DB: ChromaDB
    - ğŸ§  Embedding: all-MiniLM-L6-v2
    - ğŸ“š Dataset: turkish-law-chatbot
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ“ Akbank GenAI Bootcamp")
    st.markdown("*Yeni Nesil Proje KampÄ±*")
    
    if st.button("ğŸ”„ Sohbeti Temizle"):
        st.session_state["messages"] = [
            {
                "role": "assistant", 
                "content": "Merhaba! TÃ¼rk hukuku ile ilgili sorularÄ±nÄ±zÄ± cevaplayabilirim. NasÄ±l yardÄ±mcÄ± olabilirim? ğŸ“š"
            }
        ]
        st.rerun()
    
    # Footer
    st.markdown("---")
    st.markdown("ğŸ”— [GitHub](https://github.com/yourusername/lexmove-rag)")
    st.caption("Made with â¤ï¸ for Akbank Bootcamp")